
## 可用模型1
[[2024-03-22]]
由于作者似乎删除了dockerhub上的镜像，所以这里只能采用手动部署
经过实地在wsl中进行测试可得，测试用的应用可以正常运行，并输出结果
[Computational-Plant-Science/SMART: Monitor and analyze plant growth conditions by computing geometric and color traits from any top-view image dataset (github.com)](https://github.com/Computational-Plant-Science/SMART)
环境配置需求：
python
pipenv
依赖列表：
```txt
	 numpy
    Pillow
    scipy
    scikit-image==0.19.3
    scikit-learn
    matplotlib
    pandas
    pytest
    opencv-python-headless
    openpyxl
    imutils
    numba
    skan
    tabulate
    pylibdmtx
    psutil
    natsort
    pathlib
    kmeans1d
    rembg
```

```sh

git clone https://github.com/Computational-Plant-Science/SMART.git

```
```sh
cd ~/xxx/SMART/
pipenv install -r requirments.txt CV
```


激活虚拟环境
```sh
pipenv shell
```

接下来的步骤可以按照文档进行操作
[[2024-03-23]]
指定文件输入，输出识别结果

```sh
  python3 /opt/smart/core/trait_extract_parallel_demo.py -p /$host_path/SMART/sample_test/
```
这是一个在oyzy02wsl上的示例：
```sh
  python3 /home/oyzy2/plantCV/SMART/core/trait_extract_parallel_demo.py -p /home/oyzy2/plantCV/SMART/sample_test/
```
这是在oyzy01wsl上的示例：
```sh
 python3 /home/oyzy_work/plantCV/SMART/core/trait_extract_parallel_demo.py -p /home/oyzy_work/plantCV/SMART/sample_test/

```
其中/home/oyzy2/plantCV/SMART/sample_test/ 是输入样本图片的位置
/home/oyzy2/plantCV/SMART/core/trait_extract_parallel_demo.py 是分析模型的位置
通过一定的修改操作即可实现图片分析
分析得到的结果会输出到一个xslx文件中，大概记录了叶片的面积与颜色相关数据
==注意：这是一个对单一植株从俯视图分析其生长状况的计算机视觉模型==
所以输入图像应该是单株植物的俯视图，而不能是单片叶片，或者其他角度拍摄的植物图片，而且原文是以 拟南芥作为测试样例
还有一点，这个模型不知道是不是加载了什么识别组件，可以识别出网络上的图片的来源（）

### 测试
1.断网
2.确定能识别的图片的要求

[[2024-03-24]]
经过一定的实拍样本图片测试，这个模型能够输出部分参数（比如植株叶片面积，植株宽度，颜色等信息，只是无法写入到记录表格中去，需要对代码进行一定的修改）
以及，需要搭建一个数据库，存储原图片（有需求就存，没需求就算了）以及分析得到的各项数据，
需要搭建另一个基于时序数据分析植株生长情况的模型，
还有就是要确定多大的云服务器的性能能够支撑这个模型加上一个小型数据库


进一步测试表明这个模型不太稳定，
跑到第三张图片的时候就报错了，需要查阅官方文档进行进一步了解
如果说这个模型自带按照时序分析植物生长状况的模块的话，报错可能是因为使用的样例图片并非单植株生长的过程图片
还有一种可能是某些普通图片无法满足分析要求，因此报错
从这个角度来看，需要了解对于样例图片的具体要求
下列是一些由于干扰过多导致图片无法被识别的例子：
```
IMG_20240323_145621
IMG_20240323_145655
IMG_20240323_145657
#白色背景也是干扰
IMG_20240323_145839

```
#### 模型的具体要求
为达到更准确稳定的识别效率，需要无背光的黑色背景（泥土即可）下的植株俯视图，
白色背景的样例图片大概率使识别算法失效


### 模型拆解
大致看了看代码，感觉得先复习python
## 大概的计划
修改模型代码，使其能够输出有用的数据
数据库搭建，用于存储数据
自动化分析程序搭建，简单要求就是接收图片，调用模型处理图片，将数据按要求写入数据库
数据分析模块，分析模型得到的粗数据，实现对植株生长情况的评估
控制模块，根据数据分析得到的评估结果，向树莓派发送相应的控制指令

后端搭建，简单要求就是完成与树莓派的稳定通信，使图片以及其他数据（包括控制指令）能够可靠地传输，
以及与前端通信，向使用者展示植物的实时生长情况以及数据

能够运行这些模块，总共加起来的云服务性能需求可能比较离谱，至少需要4核处理器以及8G运行内存，外加每天产生的数据量至少有100MB,长期运行的数据库的容量应该不小于20GB


## 可用模型2
[[2024-03-23]]
模型的用法相关文档
[Welcome to openalea.phenomenal’s documentation! — Phenomenal 1.8.1 documentation](https://phenomenal.readthedocs.io/en/latest/)
在线模型运行
[Binder (mybinder.org)](https://mybinder.org/v2/gh/openalea/phenomenal/master?filepath=examples)

==突然意识到，目前好像有在线模型运行的服务，或许比自己部署要更方便==
这个模型部署起来比较麻烦，现在先跳过

## 可用模型3
一个用于训练和评估植物病害检测问题的不同 dnn 模型
使用深度学习进行植物病害检测
年代有点老了，五年前的东西，没有更新了
[spMohanty/PlantVillage-Dataset: Dataset of diseased plant leaf images and corresponding labels (github.com)](https://github.com/spMohanty/PlantVillage-Dataset)
植物疾病样例数据集
